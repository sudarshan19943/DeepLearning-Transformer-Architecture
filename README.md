# DeepLearning-Transformer-Architecture
Transformer architecture code based on the research paper "Attention is all you need" https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf forming the core basis of modern day GPT and Chat models.

The code demonstrates how an LLM would work under the hood using Tensorflow covering encoder attention, postional encodings, and multi-head attention.
